{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Helper libraries\n",
    "import sys\n",
    "sys.path.append('a3_framework')\n",
    "import a3utils, a3tf_embed_viz, a3rnnlm\n",
    "reload(a3utils)\n",
    "reload(a3tf_embed_viz)\n",
    "reload(a3rnnlm)\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "import module_preprocess\n",
    "import util, rnnlm, vocabulary1\n",
    "reload(util)\n",
    "reload(rnnlm)\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from random import randint\n",
    "\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"0.12\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "interim_path = '../..interim/'\n",
    "\n",
    "print \"Done!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samp = True\n",
    "samp = '_samp' if samp else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Feature Names Shape:', (1192, 2))\n",
      "('Descriptions Shape:', (1192, 1))\n"
     ]
    }
   ],
   "source": [
    "# Load feature names\n",
    "fnames = np.array(pd.read_pickle('../interim/028_preproc_heavy_shows_concat' + samp + '.p'))\n",
    "\n",
    "# load concatenated descriptions\n",
    "desc = np.array(pd.read_pickle('../interim/028_preproc_heavy_show_description_concat' + samp + '.p'))\n",
    "\n",
    "print(\"Feature Names Shape:\", fnames.shape)\n",
    "print(\"Descriptions Shape:\", desc.shape)\n",
    "assert fnames.shape[0] == desc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'dogs', 0.8680489659309387),\n",
       " (u'puppy', 0.8106428384780884),\n",
       " (u'pit_bull', 0.780396044254303),\n",
       " (u'pooch', 0.7627377510070801),\n",
       " (u'cat', 0.7609456777572632),\n",
       " (u'golden_retriever', 0.7500902414321899),\n",
       " (u'German_shepherd', 0.7465174198150635),\n",
       " (u'Rottweiler', 0.7437614798545837),\n",
       " (u'beagle', 0.7418621778488159),\n",
       " (u'pup', 0.740691065788269)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel = KeyedVectors.load_word2vec_format('../interim/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "w2vmodel.most_similar('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#w2vmodel.save('../interim/gensim_model')\n",
    "#w2vmodel = KeyedVectors.load('../interim/gensim_model')\n",
    "w2vmodel['dog'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reload(module_preprocess)\n",
    "lst=[]\n",
    "for i in range(0, desc.shape[0]):\n",
    "    text = module_preprocess.tokenize(desc[i][0], rmv_all_digits=True, lowercase = True, \n",
    "                                   lemmatizer=module_preprocess.lemmatizer)\n",
    "    lst.append(text)\n",
    "\n",
    "with open('../interim/descriptions_cleaned' + samp + '.p', 'wb') as f:\n",
    "    pickle.dump(lst,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('../interim/descriptions_cleaned' + samp + '.p', 'rb') as f:\n",
    "    desc_list = pickle.load(f)\n",
    "\n",
    "document_vectors = []\n",
    "for d in desc_list:\n",
    "    if len(d) > 0:\n",
    "        doc_vec = {}\n",
    "        for word in d[0]:\n",
    "            if word in w2vmodel:\n",
    "                if len(doc_vec) == 0:\n",
    "                    doc_vec = w2vmodel[word]\n",
    "                else:\n",
    "                    doc_vec = np.concatenate((doc_vec, w2vmodel[word]), axis=0)\n",
    "        document_vectors.append(doc_vec)\n",
    "\n",
    "with open('../interim/document_vectors_cleaned' + samp + '.p', 'wb') as f:\n",
    "    pickle.dump(document_vectors,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1191"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../interim/document_vectors_cleaned' + samp + '.p', 'rb') as f:\n",
    "    new_doc_vector_list = pickle.load(f)\n",
    "len(new_doc_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b', 'd'], \n",
       "      dtype='|S1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array(['a','b','c','d','e'])\n",
    "els = [1,3]\n",
    "a[els]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save descriptions\n",
    "import pickle\n",
    "filepath = '../../interim/descriptions_preprocessed_dev_samp.p'\n",
    "with open( filepath, 'rb') as f:\n",
    "    desc_list= pickle.load(f)\n",
    "filepath = '../../interim/feature_names_dev_samp.p'\n",
    "with open( filepath, 'rb') as f:\n",
    "    fn_list= pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241, 2)\n"
     ]
    }
   ],
   "source": [
    "with open( '../../interim/preprocessed_concatenated_all_samp.p') as p:\n",
    "\tpodcast_array = pickle.load(p)\n",
    "\n",
    "print podcast_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[u'U.S. Supreme Court 2010 Term Arguments',\n",
       "        'Oral arguments before the Supreme Court of the United States, presented by Oyez, a multimedia judicial archive at the IllinoisTech Chicago-Kent College of Law.'],\n",
       "       [u'Shondaland: Revealed',\n",
       "        'Join Executive Producer Betsy Beers as she takes listeners behind the scenes with the cast and creators of ABC\\'s Thursday night Shondaland shows - \"Grey\\'s Anatomy? and \"How to Get Away with Murder\" - airing Thursdays nights in primetime on ABC.'],\n",
       "       [u'She Explores',\n",
       "        'Inquisitive women in the outdoors, on the road, and besides. A podcast for and about women who are inspired by time spent outside.'],\n",
       "       [u'Insomnia Radio: Daily Dose MP3 Blog',\n",
       "        'On The Daily Dose, Insomnia Radio brings you daily mp3s, legally and with permission from the artists. One excellent song per day delivered directly to your iPod or PC. DJ Chatter and socks not included. The socks would be rocked off anyway.'],\n",
       "       [u'Law of Attraction Radio Network',\n",
       "        'Listen to Law of Attraction EXPERTS reveal their secrets through Science and Spirituality. Each show has incredible insight that will inspire you!']], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
